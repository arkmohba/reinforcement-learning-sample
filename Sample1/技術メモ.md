# 強化学習用語

* 報酬：行動と行動後の状態から判定される値。
* 行動：環境内で行う操作
* 状態：入力値であり、行動後に得られる出力でもある

## 現ステップから検討する報酬の総和

あるステップtから始めて最後のステップに至るまでの報酬の総和のこと
数式としては以下の通り。

$$
    R_t = r_t + \gamma r_{t+1} + \gamma^2 r_{t+2} + ...
        = \sum_{i=0}^{\infty} (\gamma^i r_{t+i})
$$

式変形で以下の様になる。

$$
    R_t = r_t + \gamma (r_{t+1} + \gamma r_{t+2} + ...) = r_t + \gamma(\sum_{i=0}^{\infty} (\gamma^i r_{t+1+i})) = r_t + \gamma R_{t+1}
$$

ここで $\gamma$ は割引率と呼ばれる数値。$r_t$ は各ステップの報酬。

意味としては今丁度の報酬と次回以降の報酬に分けた形になる。

ただし、 $R_t$ には行動や状態が入らないので $R_t$ の代わりに $Q(s, a)$ を使用する。

## 現ステップから考える行動価値の総和


## policy

## Q-learning